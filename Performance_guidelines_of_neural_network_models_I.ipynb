{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Performance guidelines of neural network models I.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMXSE1nJQyWa",
        "colab_type": "text"
      },
      "source": [
        "### Course Structure\n",
        "https://www.analyticsvidhya.com/blog/2018/11/neural-networks-hyperparameter-tuning-regularization-deeplearning/\n",
        "\n",
        "Part 1 of this series covered concepts like how both shallow and deep neural networks work, how to implement forward and backpropagation on single as well as multiple training examples, among other things. Now comes the question of how to tweak these neural networks in order to extract the maximum accuracy out of them.\n",
        "\n",
        "Course 2, which we will see in this article, spans three modules:\n",
        "\n",
        "* In module 1, we will be covering the practical aspects of deep learning. We will see how to split the training, validation and test sets from the given data. We will also be covering topics like regularization, dropout, normalization, etc. that help us make our model more efficient.\n",
        "* In module 2, we will discuss the concept of a mini-batch gradient descent and a few more optimizers like Momentum, RMSprop, and ADAM.\n",
        "* In the last module, we will see how different hyperparameters can be tuned to improve the modelâ€™s efficiency. We will also cover the concept of Batch Normalization and how to solve a multi-class classification challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN5TWItZ0ZHm",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/how-to-increase-the-accuracy-of-a-neural-network-9f5d1c6f407d\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJQOU67Vh1YJ",
        "colab_type": "text"
      },
      "source": [
        "## An example\n",
        "We are going to work with feed-forward networks similar to the picture adopted from Wikimedia below.\n",
        "![ Diagram of a Convolutional Neural Network](https://drive.google.com/uc?id=1l_2U8B6rjMEd86GI9f4OLGH8Ih6K00EY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inmn_ARJjTtf",
        "colab_type": "text"
      },
      "source": [
        "The image shows you that you feed an image as an input to the network, which goes through multiple convolutions, subsampling, a fully connected layer and finally outputs something.\n",
        "<br><br>\n",
        "#### The Fashion-MNIST dataset\n",
        "Fashion-MNIST is similar to the MNIST dataset that collects Zalando's article images, with 28x28 grayscale images of 70,000 fashion products from 10 categories, and 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htkJLptgATg",
        "colab_type": "text"
      },
      "source": [
        "### Loading and preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OlJMmG9lIye",
        "colab_type": "code",
        "outputId": "99c235cd-0d76-4fc6-c8aa-391a527600b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "## Load the data\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 9us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCfRKIlGljJw",
        "colab_type": "code",
        "outputId": "024f25ec-f6f4-47e8-cd6c-1f2844a866a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Analyze the data\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
        "print('Testing data shape : ', test_X.shape, test_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (60000, 28, 28) (60000,)\n",
            "Testing data shape :  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVjE0WPomaHi",
        "colab_type": "code",
        "outputId": "2955e4c1-299d-411d-bf66-00c37e16502f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "### Visualize the image examples\n",
        "\n",
        "plt.figure(figsize=[5,5])\n",
        "\n",
        "# Display the last image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_X[-1,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
        "\n",
        "# Display the last image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(test_X[-1,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAACuCAYAAABN9Xq+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5IQQpUZBTghRav4PSmpEWPNeZL4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBzynNlNm7Y6",
        "colab_type": "text"
      },
      "source": [
        "The output of above two plots looks like sandals, and this class is assigned a class label of 9. Similarly, other fashion products will have different labels, but similar products will have same labels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdcGn8GDndX2",
        "colab_type": "text"
      },
      "source": [
        "#### Data preproessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIGBy3mJnhxq",
        "colab_type": "code",
        "outputId": "482ecf27-8e92-40c5-9cc0-5e541f25ed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## data reshaping\n",
        "train_X = train_X.reshape(-1, 28,28, 1)\n",
        "test_X = test_X.reshape(-1, 28,28, 1)\n",
        "print(train_X.shape, test_X.shape)\n",
        "\n",
        "## Data format changing and normalization (data scaling)\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255.\n",
        "\n",
        "# Change the labels from categorical to one-hot encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtbBEiWzpmkC",
        "colab_type": "code",
        "outputId": "d15a8b80-6ecc-4134-c9bd-fd2feb47712d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "### Split the training data into two parts, one designed for training and another one for validation. \n",
        "### In this case, you will train the model on 80% of the training data and validate it on 20% of the remaining training data.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
        "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28, 1) (12000, 28, 28, 1) (48000, 10) (12000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nej40DIpqWQb",
        "colab_type": "text"
      },
      "source": [
        "### **A simple convolutional neural network**\n",
        "![the network architecture](https://drive.google.com/uc?id=1BWIwxK3qmCnhvqc8qWqZkAnhWMjv4CQE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOg-aZnxqbBr",
        "colab_type": "code",
        "outputId": "8cb749e0-3926-4a58-a768-4f302782742d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "## The images are of size 28 x 28. You convert the image matrix to an array, rescale it between 0 and 1, reshape it so that it's of size 28 x 28 x 1, and feed this as an input to the network. \n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 10\n",
        "#################################\n",
        "# The neural network architecture\n",
        "#################################\n",
        "\n",
        "fashion_model = Sequential()\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))   \n",
        "fashion_model.add(Dense(num_classes, activation='softmax'))              "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHoeU9QHtfym",
        "colab_type": "code",
        "outputId": "d89121e8-daea-49f0-bda4-9ca49716f590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "### Model compiling\n",
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "fashion_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 356,234\n",
            "Trainable params: 356,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA9eJMFmMXJs",
        "colab_type": "text"
      },
      "source": [
        "### Understand model performance\n",
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLh3r0iVuSSO",
        "colab_type": "code",
        "outputId": "6ff5f0cf-3104-4f89-afab-f411a38d350c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### It's time to train the model with Keras' fit() function\n",
        "fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "48000/48000 [==============================] - 20s 421us/step - loss: 0.4635 - acc: 0.8314 - val_loss: 0.3350 - val_acc: 0.8804\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 6s 126us/step - loss: 0.2907 - acc: 0.8929 - val_loss: 0.2825 - val_acc: 0.8952\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 6s 128us/step - loss: 0.2459 - acc: 0.9088 - val_loss: 0.2666 - val_acc: 0.9019\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 6s 128us/step - loss: 0.2122 - acc: 0.9219 - val_loss: 0.2660 - val_acc: 0.9054\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 6s 126us/step - loss: 0.1882 - acc: 0.9304 - val_loss: 0.2292 - val_acc: 0.9152\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 6s 130us/step - loss: 0.1642 - acc: 0.9377 - val_loss: 0.2437 - val_acc: 0.9135\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 6s 132us/step - loss: 0.1442 - acc: 0.9457 - val_loss: 0.2235 - val_acc: 0.9230\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 6s 132us/step - loss: 0.1259 - acc: 0.9529 - val_loss: 0.2251 - val_acc: 0.9244\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 129us/step - loss: 0.1083 - acc: 0.9583 - val_loss: 0.2535 - val_acc: 0.9180\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 6s 129us/step - loss: 0.0908 - acc: 0.9668 - val_loss: 0.2717 - val_acc: 0.9207\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 6s 128us/step - loss: 0.0781 - acc: 0.9705 - val_loss: 0.2774 - val_acc: 0.9197\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 6s 130us/step - loss: 0.0650 - acc: 0.9757 - val_loss: 0.3229 - val_acc: 0.9189\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 130us/step - loss: 0.0543 - acc: 0.9799 - val_loss: 0.2998 - val_acc: 0.9216\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 128us/step - loss: 0.0491 - acc: 0.9822 - val_loss: 0.3267 - val_acc: 0.9218\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 129us/step - loss: 0.0454 - acc: 0.9826 - val_loss: 0.3560 - val_acc: 0.9222\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 128us/step - loss: 0.0391 - acc: 0.9854 - val_loss: 0.3558 - val_acc: 0.9211\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 127us/step - loss: 0.0379 - acc: 0.9860 - val_loss: 0.4069 - val_acc: 0.9178\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 6s 126us/step - loss: 0.0345 - acc: 0.9877 - val_loss: 0.3834 - val_acc: 0.9226\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 127us/step - loss: 0.0287 - acc: 0.9893 - val_loss: 0.4039 - val_acc: 0.9227\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 126us/step - loss: 0.0340 - acc: 0.9876 - val_loss: 0.4315 - val_acc: 0.9210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL_in_opuw9z",
        "colab_type": "text"
      },
      "source": [
        "You trained the model on fashion-MNIST for 20 epochs, and by observing the training accuracy and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2fqYzntLsXB",
        "colab_type": "text"
      },
      "source": [
        "### Check for overfitting\n",
        "* We can first ensure the neural network performs well on the testing data to verify that the neural network does not overfit. <br>\n",
        "* What is overfitting? <br>\n",
        "<I><font color=7714e6> In machine learning, overfitting is a phenomenon where a machine learning model models the training data too well but fails to perform well on the testing data. Performing sufficiently good on testing data is considered as a kind of ultimatum in machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btutrzCx1DWo",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export&id=1FiZDQG5RngJb7CAa8Cp4cUr8w-YQgf1C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rahEALIJcoab",
        "colab_type": "text"
      },
      "source": [
        "#### How to identify if your model is overfitting?<br> \n",
        "You can just cross check the training accuracy and testing accuracy. If training accuracy is much higher than testing accuracy then you can posit that your model has overfitted. <br>\n",
        "You can also plot the predicted points on a graph to verify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5KJpQ7vabm",
        "colab_type": "text"
      },
      "source": [
        "#### Model evauation on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpX3yRvnvgBU",
        "colab_type": "code",
        "outputId": "206c6425-0902-43e2-be31-f0c22330bf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 54us/step\n",
            "Test loss: 0.49096115071699026\n",
            "Test accuracy: 0.9038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHPv-sidwZjr",
        "colab_type": "code",
        "outputId": "58ef4676-30ff-473f-9962-66167ed30834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "## put the model evaluation into perspective and plot the accuracy and loss plots between training and validation data\n",
        "accuracy = fashion_train.history['acc']\n",
        "val_accuracy = fashion_train.history['val_acc']\n",
        "loss = fashion_train.history['loss']\n",
        "val_loss = fashion_train.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(12,6))\n",
        "\n",
        "ax1.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax1.title.set_text('Training and validation accuracy')\n",
        "ax1.legend()\n",
        "#plt.figure()\n",
        "ax2.plot(epochs, loss, 'bo', label='Training loss')\n",
        "ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "ax2.legend()\n",
        "ax2.title.set_text('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAF1CAYAAAAXywc5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZgU1dn///fNIvsmYDQgi0qQYXUY\ngTygLG5o4oIrOKgQDdFETTSaoKAQDJoYjWhCTNAfrijy1UfFiCEaUeLjEgZEEAyLiDLgwr6rLPfv\nj1MzNMMsPTM909PTn9d11dVVp6pOneoeirtPn8XcHRERERERKVmNZBdARERERCRVKHgWEREREYmT\ngmcRERERkTgpeBYRERERiZOCZxERERGROCl4FhERERGJk4LnasbMaprZDjNrk8hjk8nMjjOzhI+p\naGanmtnqmO1lZnZSPMeW4VoPm9mtZT1fRKQweuaXKt+Uf+ab2W/N7NFE5yulUyvZBUh3ZrYjZrM+\n8A2wL9r+ibtPK01+7r4PaJjoY9OBu3dMRD5mdhUw3N0HxOR9VSLyFpHUpmd+1aFnvpSVguckc/f8\nB1n0Lfcqd3+tqOPNrJa7762MsomURH+PIqWjZ75I6lOzjSou+onmGTN72sy2A8PN7Ptm9q6ZbTGz\nz83sATOrHR1fy8zczNpF209G+18xs+1m9o6ZtS/tsdH+M81suZltNbM/mdn/mdmIIsodTxl/YmYr\nzWyzmT0Qc25NM7vPzDaa2SpgcDHvzxgzm14gbbKZ/TFav8rMPoru5+OohqCovHLNbEC0Xt/MnojK\ntgToWeDYsWa2Ksp3iZmdE6V3Bf4MnBT9PLoh5r0dH3P+1dG9bzSzF8zsqHjem9K8z3nlMbPXzGyT\nmX1hZr+Kuc5t0XuyzcxyzOy7hf1camZv5X3O0fs5N7rOJmCsmXUwsznRNTZE71uTmPPbRve4Ptp/\nv5nVjcrcKea4o8xsl5k1L+p+Rao7PfP1zC/umV/IPQyJyrPFzF43s44x+241s3XRM/6/Mffax8wW\nROlfmtkf4r2eRNxdSxVZgNXAqQXSfgt8C5xN+LJTDzgR6E345eAYYDlwbXR8LcCBdtH2k8AGIAuo\nDTwDPFmGY48AtgPnRvtuBPYAI4q4l3jK+CLQBGgHbMq7d+BaYAnQGmgOzA1/qoVe5xhgB9AgJu+v\ngKxo++zoGAMGAbuBbtG+U4HVMXnlAgOi9XuAN4BmQFtgaYFjLwaOij6TS6MyfCfadxXwRoFyPgmM\nj9ZPj8rYA6gL/AV4PZ73ppTvcxPgS+DnQB2gMdAr2ncL8AHQIbqHHsDhwHEF32vgrbzPObq3vcA1\nQE3C3+P3gFOAw6K/k/8D7om5nw+j97NBdHzfaN8UYGLMdX4JPJ/sf4datFTWgp75euaX/pn/W+DR\naL1TVI5B0Wd0K7AsWu8MfAocGR3bHjgmWp8HDIvWGwG9k/1vIdUW1Tynhrfc/SV33+/uu919nru/\n5+573X0VIQjpX8z5z7p7jrvvAaYR/gGX9tgfAgvd/cVo332Eh26h4izjXe6+1d1XEx5aede6GLjP\n3XPdfSPwu2Kus4oQnJ0bJZ0GbHb3nGj/S+6+yoPXgX8BhXYQKeBi4LfuvtndPyXULMRed4a7fx59\nJk8R/hPMiiNfgGzgYXdf6O5fA6OB/mbWOuaYot6bg5TwPp8DfObu97v7N+6+zd3/E+27CrjV3VdE\n97DQ3TfFWf7P3P1Bd98X/T0ud/d/ufu37v4V4W8jrwzfB1oAv3b3ndHx/xftewy41Mws2r4MeCLO\nMohUZ3rmF32dtH7mFzAUmOnur0ef0e8IAXhvQiVHXaCzhaY/n0TvHYQvQR3MrLm7b3f39+K8D4ko\neE4Na2I3zOx4M3vZws/w24AJhAClKF/ErO+i+A4jRR373dhyuLsTvrUXKs4yxnUtwrfn4jwFDIvW\nL42288rxQzN7z0KTgi2EGoDi3qs8RxVXBjMbYWYfRD+VbQGOjzNfCPeXn5+7bwM2A61ijonrMyvh\nfT4a+LiIMhS3ryQF/x6PNLMZZrY2KsOjBcqw2kNHpYNEQfReoJ+ZdQHaAC+XsUwi1Yme+cVL22d+\nCfnuJ3xGrdx9GeHXvAnAVxaaAR0ZHToSyACWmdl/zOysOO9DIgqeU0PBIXv+RvjmfZy7NwZuJ/xE\nVZE+J/ykBkBUW9iq6MPLVcbPCUFXnpKGVZoBnGpmrQi1EU9FZawHPAvcRfh5rSnwzzjL8UVRZTCz\nY4AHCU0Xmkf5/jcm35KGWFpH+FkwL79GhJ8K18ZRroKKe5/XAMcWcV5R+3ZGZaofk3ZkgWMK3t/v\nCSMGdI3KMKJAGdqaWc0iyvE4MJxQ6zzD3b8p4jiRdKJnfvHS+ZlfXL41CJ/ZWgB3f9Ld+xKabNQk\nvC+4+zJ3H0pomnMv8JyZ1S1nWdKKgufU1AjYCuy00OHqJ5Vwzb8DmWZ2tpnVIrSjbVlBZZwB/MLM\nWlnoPPbr4g529y8I7XIfBZa5+4poVx1CO9z1wD4z+yGhbW68ZbjVzJpaGBP12ph9DQkPy/WE/1N+\nTKiFyPMl0NpiOu4V8DRwpZl1M7M6hAfav929yFqdYhT3Ps8E2pjZtWZWx8wam1mvaN/DwG/N7FgL\nepjZ4YT/QL4gdFKqaWajiHk4F1OGncBWMzsauClm3zvARuBOCx1y6plZ35j9TwAXEmqPHi/D/Yuk\nAz3zY6T5M79gmc8xswHRtW8mtFN/z8w6mdnA6Hq7o2U/4QYuM7MWUU311uje9pezLGlFwXNq+iVw\nBeEfyd8InTwqlLt/CVwC/JEQDB0LvE+ocUx0GR8ktFNbTOjY8Gwc5zxF6AyS//Odu28BbgCeJ3TA\nuJDwH0I8xhFqQ1YDrxAT2Ln7IuBPwH+iYzoCsW3GXgVWAF+aWexPcXnn/4PwU9rz0fltCG3iyqLI\n99ndtxLaA15AeLgv50AbxD8ALxDe522E9ol1o59mf0zoeLKB0IGwpPZw44BehIfwTOC5mDLsJbSd\n7ESohf6M8Dnk7V9N+Jy/cfe3S3nvIulCz/xDpeszPzbfJYT3/EFCYD8YOCdq/1wHuJvwHP+CUNM9\nJjr1LOAjC6O53ANc4u7flrc86cTC/5UipRP9DL8OuNDd/53s8kjqMrPHgVXuPj7ZZRGRwumZL3KA\nap4lbmY2OPpJqw5wG6HH7n9KOE2kSFFbwnOBqckui4gcTM98kcIpeJbS6AesIvw8dAYwRB28pKzM\n7C7CWNN3uvtnyS6PiBxCz3yRQqjZhoiIiIhInFTzLCIiIiISJwXPIiIiIiJxqpXsApRGixYtvF27\ndskuhohIqc2fP3+Duxc3Tm61o2e2iKSq4p7ZKRU8t2vXjpycnGQXQ0Sk1MyspCmHqx09s0UkVRX3\nzFazDRERERGROCl4FhERERGJk4JnEREREZE4pVSb58Ls2bOH3Nxcvv7662QXRaqIunXr0rp1a2rX\nrp3sooiISBpSbJI6yhIzpHzwnJubS6NGjWjXrh1mluziSJK5Oxs3biQ3N5f27dsnuzgiVYqZTQV+\nCHzl7l0K2X8zkB1t1gI6AS3dfZOZrQa2A/uAve6eVTmlFkk9ik1SQ1ljhriabUTz2y8zs5VmNrqQ\n/W3N7F9mtsjM3jCz1lH6QDNbGLN8bWbnRfseNbNPYvb1iLvUMb7++muaN2+uP04BwMxo3ry5vu2L\nFO5RYHBRO939D+7ew917ALcAb7r7pphDBkb7FTiLFEOxSWooa8xQYs2zmdUEJgOnAbnAPDOb6e5L\nYw67B3jc3R8zs0HAXcBl7j4H6BHlcziwEvhnzHk3u/uzpSpx4WUsbxZSjejvQaRw7j7XzNrFefgw\n4OmKK41I9ab/i1JDWT6neGqeewEr3X2Vu38LTAfOLXBMBvB6tD6nkP0AFwKvuPuuUpeyCtu4cSM9\nevSgR48eHHnkkbRq1Sp/+9tvv40rj5EjR7Js2bJij5k8eTLTpk1LRJFFRIplZvUJNdTPxSQ78E8z\nm29mo5JTMhEpSSrGJf369WPhwoUJyasyxNPmuRWwJmY7F+hd4JgPgPOB+4EhQCMza+7uG2OOGQr8\nscB5E83sduBfwGh3/6bgxaOH9CiANm3axFHc4k2bBmPGwGefQZs2MHEiZGeXfF5Rmjdvnv+Bjx8/\nnoYNG3LTTTcddIy74+7UqFH4d5VHHnmkxOv87Gc/K3shk2Tv3r3UqpXyzepF0tHZwP8VaLLRz93X\nmtkRwKtm9l93n1vwxEQ/s0XSQSJjE8UlFS9RQ9XdBPQ3s/eB/sBaQqcSAMzsKKArMDvmnFuA44ET\ngcOBXxeWsbtPcfcsd89q2bJ8M9tOmwajRsGnn4J7eB01KqQn2sqVK8nIyCA7O5vOnTvz+eefM2rU\nKLKysujcuTMTJkzIPzbvG9fevXtp2rQpo0ePpnv37nz/+9/nq6++AmDs2LFMmjQp//jRo0fTq1cv\nOnbsyNtvvw3Azp07ueCCC8jIyODCCy8kKyur0G9y48aN48QTT6RLly5cffXVuDsAy5cvZ9CgQXTv\n3p3MzExWr14NwJ133knXrl3p3r07Y8aMOajMAF988QXHHXccAA8//DDnnXceAwcO5IwzzmDbtm0M\nGjSIzMxMunXrxt///vf8cjzyyCN069aN7t27M3LkSLZu3coxxxzD3r17Adi8efNB2yKJMG0atGsH\nNWqEV/2gU6ihFGiy4e5ro9evgOcJv0oeojzPbH02ko4qKzapynFJrCeffJKuXbvSpUsXbr31ViBU\nxl122WX56Q888AAA9913HxkZGXTr1o3hw4cn9g0rTt63j6IW4PvA7JjtW4Bbijm+IZBbIO3nwJRi\nzhkA/L2ksvTs2dMLWrp06SFpRWnb1j38aR68tG0bdxbFGjdunP/hD39wd/cVK1a4mfm8efPy92/c\nuNHd3ffs2eP9+vXzJUuWuLt73759/f333/c9e/Y44LNmzXJ39xtuuMHvuusud3cfM2aM33ffffnH\n/+pXv3J39xdffNHPOOMMd3e/6667/Kc//am7uy9cuNBr1Kjh77///iHlzCvH/v37fejQofnXy8zM\n9JkzZ7q7++7du33nzp0+c+ZM79evn+/ateugc/PK7O7++eef+7HHHuvu7g899JC3adPGN23a5O7u\n3377rW/dutXd3b/88ks/7rjj8svXsWPH/PzyXocPH+4vvfSSu7tPnjw5/z5LqzR/F5I+nnzSvX79\ng//9168f0isakOMlPOMqYwHaAR8Ws78JsAloEJPWAGgUs/42MLikaxX2zC5KMj8bkUSrKrFJqsQl\neddbs2aNt23b1tevX+/ffvutn3zyyf7SSy/5u+++64MHD84/fvPmze7ufuSRR/o333xzUFpZFPZ5\nFffMjqfmeR7Qwczam9lhhBqJmbEHmFkLM8vL6xZgaoE8Dul4EtVGY6Gl9nnAh3GUpVw++6x06eV1\n7LHHkpV1oFP6008/TWZmJpmZmXz00UcsXbr0kHPq1avHmWeeCUDPnj3za38LOv/88w855q233mLo\n0KEAdO/enc6dOxd67r/+9S969epF9+7defPNN1myZAmbN29mw4YNnH322UAY97B+/fq89tpr/OhH\nP6JevXoAHH744SXe9+mnn06zZs2A8OVs9OjRdOvWjdNPP501a9awYcMGXn/9dS655JL8/PJer7rq\nqvyfix555BFGjhxZ4vUk/ZS1hnLMGNhVoNfFrl0hvaKuWZWY2dPAO0BHM8s1syvN7GozuzrmsCHA\nP919Z0zad4C3zOwD4D/Ay+7+j0SWrTyfjUgqq8zYpKrGJXnee+89Bg0aRIsWLahduzaXXnopc+fO\n5bjjjmPZsmVcf/31zJ49myZNmgDQuXNnhg8fzrRp0yp1bocSG6S6+14zu5bQ5KImMNXdl5jZBEJU\nPpNQc3yXmTkwF8hvCBP17D4aeLNA1tPMrCVgwELgaipYmzbh55DC0itCgwYN8tdXrFjB/fffz3/+\n8x+aNm3K8OHDCx0a5bDDDstfr1mzZpFNFurUqVPiMYXZtWsX1157LQsWLKBVq1aMHTu2TMO61apV\ni/379wMccn7sfT/++ONs3bqVBQsWUKtWLVq3bl3s9fr378+1117LnDlzqF27Nscff3ypyybVW95P\nnHmBVt5PnFByG8Gy/idVnmtWJe4+LI5jHiUMaRebtgroXjGlCiq7ckOkqqjM2KQqxiXxaN68OYsW\nLeKVV15h8uTJPPfcc0yZMoXZs2fz5ptvMnPmTO68804WLVpEzZo1E3rtwsTV5tndZ7n799z9WHef\nGKXdHgXOuPuz7t4hOuYqj+n45+6r3b2Vu+8vkOcgd+/q7l3cfbi770jkjRVm4kSoX//gtPr1Q3pF\n27ZtG40aNaJx48Z8/vnnzJ49u+STSqlv377MmDEDgMWLFxf6DXL37t3UqFGDFi1asH37dp57LnSm\nb9asGS1btuSll14CQkC8a9cuTjvtNKZOncru3bsB2LQp9B9q164d8+fPB+DZZ4sebXDr1q0cccQR\n1KpVi1dffZW1a9cCMGjQIJ555pn8/PJeAYYPH052drZqnaVQ5amhLOo/o5L+k1KtaMUr62cjkuqS\nFZtUlbgkVu/evZkzZw4bN25k7969TJ8+nf79+7N+/XrcnYsuuogJEyawYMEC9u3bR25uLoMGDeLu\nu+9mw4YN7Cr4oK4gieowmBKys2HKFGjbFszC65QplVNzlJmZSUZGBscffzyXX345ffv2Tfg1rrvu\nOtauXUtGRga/+c1vyMjIyP9pI0/z5s254ooryMjI4Mwzz6R37wMDp0ybNo17772Xbt260a9fP9av\nX88Pf/hDBg8eTFZWFj169OC+++4D4Oabb+b+++8nMzOTzZs3F1mmyy67jLfffpuuXbsyffp0OnTo\nAISfb371q19x8skn06NHD26++eb8c7Kzs9m6dSuXXHJJIt8eqSbKU0NZ1v+kVCta8ZJZuSGSTMmK\nTapKXBKrdevW3HHHHQwYMIAePXrQp08ffvCDH7BmzZr8eGHkyJHceeed7N27l0svvZRu3bqRmZnJ\nTTfdRKNGjRJ+D4UqqjF0VVzK22GwutuzZ4/v3r3b3d2XL1/u7dq18z179iS5VKX39NNP+4gRI8qV\nh/4uqq/ydq558slwrFl4jadDWiI69FBFOgxW5lKaDoPuZftsRKoi/R8UpEpcUhEdBiVF7Nixg759\n+9K9e3cuuOAC/va3v6XcOMvXXHMNt912G2PHjk12USRO5elIV5Zzy1tDmZ0Nq1fD/v3hNZ7aHdWK\nVo6yfDYiUnVVh7ikMKl/B5KvadOm+e2QU9WDDz6Y7CJIKZSnI11Zz83bl8jJjkqSjGuKiKS66hCX\nFEY1zyJSZuXpSFeec5NRQ6laURERAQXPIhIpSxOK8nSkUyc8ERFJRQqeRaTM08OWZ3gxDU0mIiKp\nSMGziJS5CUV5OtKpE56IiKQiBc/lNHDgwEMGFp80aRLXXHNNsec1bNgQgHXr1nHhhRcWesyAAQPI\nyckpNp9JkyYdNCj4WWedxZYtW+Ipuki+sjahKM/4pMkcd11EpDqrrrHJ+PHjueeee8qdT3kpeC6n\nYcOGMX369IPSpk+fzrBhJc6CC8B3v/vdYmfoK0nBP9BZs2bRtGnTMudX2dw9f5pvSZ7yNKEoT0c6\ndcITEUk8xSYVS8FzOV144YW8/PLLfPvttwCsXr2adevWcdJJJ7Fjxw5OOeUUMjMz6dq1Ky+++OIh\n569evZouXboAYersoUOH0qlTJ4YMGZI/JTaE8Y+zsrLo3Lkz48aNA+CBBx5g3bp1DBw4kIEDBwJh\n2uwNGzYA8Mc//pEuXbrQpUsXJk2alH+9Tp068eMf/5jOnTtz+umnH3SdPC+99BK9e/fmhBNO4NRT\nT+XLL78EwpiNI0eOpGvXrnTr1i1/eu9//OMfZGZm0r17d0455RTg0G+IXbp0YfXq1axevZqOHTty\n+eWX06VLF9asWVPo/QHMmzeP//mf/6F79+706tWL7du3c/LJJ7Nw4cL8Y/r168cHH3xQqs+tuirr\nmMtqQiEiUn1U19gk1sKFC+nTpw/dunVjyJAh+bMdP/DAA2RkZNCtWzeGDh0KwJtvvkmPHj3o0aMH\nJ5xwAtu3by/zewvVbJznX/wCYmKqhOjRA6LPtlCHH344vXr14pVXXuHcc89l+vTpXHzxxZgZdevW\n5fnnn6dx48Zs2LCBPn36cM4552Bmheb14IMPUr9+fT766CMWLVpEZmZm/r6JEydy+OGHs2/fPk45\n5RQWLVrE9ddfzx//+EfmzJlDixYtDspr/vz5PPLII7z33nu4O71796Z///40a9aMFStW8PTTT/PQ\nQw9x8cUX89xzzzF8+PCDzu/Xrx/vvvsuZsbDDz/M3Xffzb333ssdd9xBkyZNWLx4MQCbN29m/fr1\n/PjHP2bu3Lm0b9+eTZs2lfi+rlixgscee4w+ffoUeX/HH388l1xyCc888wwnnngi27Zto169elx5\n5ZU8+uijTJo0ieXLl/P111/TvXv3Eq9Z3ZVnzGWNYywiUjEUmxxQ3tgk1uWXX86f/vQn+vfvz+23\n385vfvMbJk2axO9+9zs++eQT6tSpk99U5J577mHy5Mn07duXHTt2ULdu3VK824dSzXMCxP48Evuz\niLtz66230q1bN0499VTWrl2bX4NbmLlz5+b/oXTr1o1u3brl75sxYwaZmZmccMIJLFmyhKVLlxZb\nprfeeoshQ4bQoEEDGjZsyPnnn8+///1vANq3b0+PHj0A6NmzJ6tXrz7k/NzcXM444wy6du3KH/7w\nB5YsWQLAa6+9xs9+9rP845o1a8a7777LySefTPv27YHwj7Ykbdu2zQ+ci7q/ZcuWcdRRR3HiiScC\n0LhxY2rVqsVFF13E3//+d/bs2cPUqVMZMWJEiddLB+UZNxnUhEJEpDqpjrFJnq1bt7Jlyxb69+8P\nwBVXXMHcuXPzy5idnc2TTz6ZP5th3759ufHGG3nggQfYsmVLuWc5rFY1z8V9C6tI5557LjfccAML\nFixg165d9OzZE4Bp06axfv165s+fT+3atWnXrh1ff/11qfP/5JNPuOeee5g3bx7NmjVjxIgRZcon\nT506dfLXa9asWehPI9dddx033ngj55xzDm+88Qbjx48v9XVq1ap1UHvm2DI3aNAgf72091e/fn1O\nO+00XnzxRWbMmFEtZy8qC42bLCJS9Sg2iU88sUk8Xn75ZebOnctLL73ExIkTWbx4MaNHj+YHP/gB\ns2bNom/fvsyePZvjjz++zGVVzXMCNGzYkIEDB/KjH/3ooMb4W7du5YgjjqB27drMmTOHTz/9tNh8\nTj75ZJ566ikAPvzwQxYtWgTAtm3baNCgAU2aNOHLL7/klVdeyT+nUaNGhbbdOemkk3jhhRfYtWsX\nO3fu5Pnnn+ekk06K+562bt1Kq1atAHjsscfy00877TQmT56cv71582b69OnD3Llz+eSTTwDym220\na9eOBQsWALBgwYL8/QUVdX8dO3bk888/Z968eQBs376dvXv3AnDVVVdx/fXXc+KJJ9KsWbO47ysV\nlLXdssZNFhGRPNUxNsnTpEkTmjVrll9r/cQTT9C/f3/279/PmjVrGDhwIL///e/ZunUrO3bs4OOP\nP6Zr1678+te/5sQTT+S///1vqa8Zq1rVPCfTsGHDGDJkyEG9W7Ozszn77LPp2rUrWVlZJX7Lueaa\naxg5ciSdOnWiU6dO+d8Su3fvzgknnMDxxx/P0UcfTd++ffPPGTVqFIMHD+a73/0uc+bMyU/PzMxk\nxIgR9OrVCwjB5gknnFDszyCxxo8fz0UXXUSzZs0YNGhQfuA7duxYfvazn9GlSxdq1qzJuHHjOP/8\n85kyZQrnn38++/fv54gjjuDVV1/lggsu4PHHH6dz58707t2b733ve4Veq6j7O+yww3jmmWe47rrr\n2L17N/Xq1eO1116jYcOG9OzZk8aNGzNy5Mi47idVlKfd8sSJB58L6vQnIpLOqltsEuuxxx7j6quv\nZteuXRxzzDE88sgj7Nu3j+HDh7N161bcneuvv56mTZty2223MWfOHGrUqEHnzp0588wzS329WObu\n5cqgMmVlZXnBsQU/+ugjOnXqlKQSSbKsW7eOAQMG8N///pcaNQ79ASVV/y7atQsBc0Ft24Z2yCWZ\nNk2d/qoqM5vv7lnJLkdlKuyZLZIOUvX/oHRV2OdV3DNbzTYk5Tz++OP07t2biRMnFho4p7LytltW\npz8REZGKVb0iD0kLl19+OWvWrOGiiy5KdlESTu2WRUREqjYFzyJViCYrERERqdqqRfCcSu22peKl\n8t9DdjZMmRLaOJuF1ylT1PxCRCTVpPL/RemkLJ9Tyo+2UbduXTZu3Ejz5s2LnB1H0oe7s3HjxnLP\nHpRM2dkKlkVEUplik9RQ1pgh5YPn1q1bk5uby/r165NdFKki6tatS+vWrZNdDBERSVOKTVJHWWKG\nlA+ea9eunT8ttEiilWfoNw0bJyKSnhSbVG8pHzyLVJTyTFhSnnNFRESk6qoWHQZFKsKYMQfP1gdh\ne8yYij1XREREqi4FzyJFKM+EJeWd7ERERESqJgXPIkUoz4QlmuxERESkelLwLFKE8kxYoslORERE\nqicFzyJFKM+EJZrsREREpHqKa7QNMxsM3A/UBB52998V2N8WmAq0BDYBw909N9q3D1gcHfqZu58T\npbcHpgPNgfnAZe7+bbnvSCSByjNhiSY7ERERqX5KrHk2s5rAZOBMIAMYZmYZBQ67B3jc3bsBE4C7\nYvbtdvce0XJOTPrvgfvc/ThgM3BlOe5DRERERKTCxdNsoxew0t1XRTXD04FzCxyTAbwerc8pZP9B\nLMxVOQh4Nkp6DDgv3kKLlNa0adCuHdSoEV6nTUt2iURERCQVxRM8twLWxGznRmmxPgDOj9aHAI3M\nrHm0XdfMcszsXTPLC5CbA1vcfW8xeQJgZqOi83M0zaWURd6EJZ9+Cu4HJixRAC0iIiKllagOgzcB\n/c3sfaA/sBbYF+1r6+5ZwKXAJDM7tjQZu/sUd89y96yWLVsmqLiSTjRhiYiIiCRKPMHzWuDomO3W\nUVo+d1/n7ue7+wnAmChtS54zCFUAACAASURBVPS6NnpdBbwBnABsBJqaWa2i8hRJFE1YIhKY2VQz\n+8rMPixi/wAz22pmC6Pl9ph9g81smZmtNLPRlVdqEZGqJZ7geR7Qwczam9lhwFBgZuwBZtbCzPLy\nuoUw8gZm1szM6uQdA/QFlrq7E9pGXxidcwXwYnlvRqq3srZb1oQlIvkeBQaXcMy/Yzp5T4C4O46L\niKSFEoPnqF3ytcBs4CNghrsvMbMJZpY3esYAYJmZLQe+A+RNBdEJyDGzDwjB8u/cfWm079fAjWa2\nktAG+v9L0D1JNVSedsuasEQkcPe5hOFESyuejuMiImkhrnGe3X0WMKtA2u0x689yYOSM2GPeBroW\nkecqwgNZpETFtVsuaSzlvP1jxoSmGm3ahMBZYzCLFOr7UYXHOuAmd19C4R3HeyejcCIiyRZX8CyS\nbOVtt6wJS0TisoDQyXuHmZ0FvAB0KE0GZjYKGAXQRm2jRKQa0vTckhLUblmk4rn7NnffEa3PAmpH\n/VVK7Dgek4dGSBKRak3Bs6QEtVsWqXhmdmQ0iRVm1ovwf8RG4ug4LiKSLhQ8S6Ury6gZ2dkwZQq0\nbQtm4XXKFDXFECkNM3saeAfoaGa5ZnalmV1tZldHh1wIfBi1eX4AGOpBoR3Hk3EPIiLJZmHUuNSQ\nlZXlOTk5yS6GlEPeqBmxnf/q11cgLNWfmc2PJoxKG3pmi0iqKu6ZrZpnqVSa7U9ERERSmYJnqVSa\n7U9ERERSmYJnqVQaNUNERERSmYJnqVQaNUNERERSmYJnqVQaNUNERERSmWYYlEqn2f5EREQkVanm\nWUREREQkTgqepUzKMtGJiIiISKpTsw0ptYITnXz6adgGNccQERGR6k01z1JqmuhERERE0pWCZyk1\nTXQiIiIi6UrBs5SaJjoRERGRdKXgWUpNE52IiIhIulLwLKWmiU5EREQkXSl4TmPlGW4uOxtWr4b9\n+8OrAmcRERFJBxqqLk1puDkRERGR0lPNc5rScHMiIiIipafgOU1puDkRERGR0lPwnKY03JyIiIhI\n6Sl4TlMabk5ERESk9BQ8pykNNyciIiJSegqeq4GyDjmn4eZERERESkdD1aU4DTknIiIiUnlU85zi\nNOSciIiISOVR8JziNOSciIiISOWJK3g2s8FmtszMVprZ6EL2tzWzf5nZIjN7w8xaR+k9zOwdM1sS\n7bsk5pxHzewTM1sYLT0Sd1vpQ0POiYiIiFSeEoNnM6sJTAbOBDKAYWaWUeCwe4DH3b0bMAG4K0rf\nBVzu7p2BwcAkM2sac97N7t4jWhaW817SkoacExEREak88dQ89wJWuvsqd/8WmA6cW+CYDOD1aH1O\n3n53X+7uK6L1dcBXQMtEFFwCDTknIiIiUnniCZ5bAWtitnOjtFgfAOdH60OARmbWPPYAM+sFHAZ8\nHJM8MWrOcZ+Z1Sns4mY2ysxyzCxn/fr1cRQ3/WjIOREREZHKkagOgzcB/c3sfaA/sBbYl7fTzI4C\nngBGuvv+KPkW4HjgROBw4NeFZezuU9w9y92zWrZUpbWIiIiIJE884zyvBY6O2W4dpeWLmmScD2Bm\nDYEL3H1LtN0YeBkY4+7vxpzzebT6jZk9QgjARURERESqrHhqnucBHcysvZkdBgwFZsYeYGYtzCwv\nr1uAqVH6YcDzhM6EzxY456jo1YDzgA/LcyMiIiIiIhWtxODZ3fcC1wKzgY+AGe6+xMwmmNk50WED\ngGVmthz4DpA31sPFwMnAiEKGpJtmZouBxUAL4LeJuikRERERkYoQ1/Tc7j4LmFUg7faY9WeBZws5\n70ngySLyHFSqkoqIiIiIJJlmGKwipk2Ddu2gRo3wOm1askskIiIiIgXFVfMsFWvaNBg1CnbtCtuf\nfhq2QcPOiYiIiFQlqnmuAsaMORA459m1K6SLiCSKmU01s6/MrNAO2maWHY29v9jM3jaz7jH7Vkfp\nC80sp/JKLSJStSh4rgI++6x06SIiZfQoMLiY/Z8A/d29K3AHMKXA/oHu3sPdsyqofCIiVZ6C5yqg\nTZvSpYuIlIW7zwU2FbP/bXffHG2+SxjXX0REYih4rgImToT69Q9Oq18/pIuIJMmVwCsx2w7808zm\nm9moJJVJRCTp1GGwCsjrFDhmTGiq0aZNCJzVWVBEksHMBhKC534xyf3cfa2ZHQG8amb/jWqyC547\nChgF0EY/n4lINaSa5yoiOxtWr4b9+8OrAmcRSQYz6wY8DJzr7hvz0t19bfT6FWHm2F6Fne/uU9w9\ny92zWrZsWRlFFhGpVAqeRUQEADNrA/wvcJm7L49Jb2BmjfLWgdOBQkfsEBGp7tRsQ0QkTZjZ08AA\noIWZ5QLjgNoA7v5X4HagOfAXMwPYG42s8R3g+SitFvCUu/+j0m9ARKQKUPAsIpIm3H1YCfuvAq4q\nJH0V0P3QM0RE0o+abYiIiIiIxEk1zyKSkhYuhLlzoW5dqFfv4KV+/cLT6taFGqoyEBGRclDwLFLN\nuENomlr97N8Ps2bBH/8Ic+aULY86dUIgPXgwjBsHHTsmtowiIlK9KXgWqWL274edO2HbNtiypXTL\n5s3htVUrOO+8sJx0EtRK8X/pu3fD44/DfffBsmXQujXcfTdceumB/bt3w65dB9YLLrH7Nm6E6dPh\nmWdg+HC47TY47rjk3qOIiKSGFP8vVaRq2r8f1qyB5cth/foQCG/bBtu3H1gvuJ23vn17qD0uTr16\n0LTpgaVlS+jQIaw3aQJLl8KUKfDAA3D44fDDH4ZA+vTToUGDynkPEuHLL2HyZHjwQdiwATIzYdo0\nuOgiqF27fHnfeWcIwCdPDnmOGAFjx0K7dokouYiIVFcKnhNs2jTNFJhOtm0LNaEFlxUrQg1nQTVq\nQKNG0LjxgaVJEzj66APbsftjA+S8pUmT0PSgJDt3wj//CS+8AC+9FGpu69ULAfR554WAukWLxL8n\nibBkSWia8eSTsGcPnH023HgjnHxy4pqkHHEE3HMP/PKX8Lvfwd/+Ft6jK6+EW28Nn4mIiEhB5iVV\ncVUhWVlZnpOTk+xiFGnaNBg1Kvw8nKd+/VADqAA6dbnDqlXw0UchMF6+/ECQ/MUXB46rWRPatw9t\naDt2hO99L7weddSBYLh+/eS0R96zB956KwTSL7wQvtzVqBGadOQ170h2jas7vPYa3HsvzJ4dAv0R\nI+AXvwjvZUXLzQ210Q8/HD6jn/wEbrklfH6JYGbzozGT00ZVf2aLiBSluGe2gucEatcOPv300PS2\nbcOU25J6du8OAdyMGQfSmjc/ECDHLsceC4cdlrSixs0d3n//QCC9eHFI79EDfvCD0ASkdu3QTrqw\n10Tsi/0C8c038PTToaZ58WL4znfguutC8JqMmvFPP4Xf/hYeeSSU9ZprYPToUFNdHgqeRURSh4Ln\nSlKjRuFtVc1CG9jq4MsvIScH5s0Lrxs2QMOGoR1t3mvsenGvTZqEZgh16yb7rgr3xRdw7rnhXseO\nhTPPDDWgzZsnu2SJ9fHH8OKLIZB+662S21snQo0aBwLqvXvh66+ha9fQNGPYsPiapVS0jz+GO+6A\nJ54If6PXXQc33VT2gF7Bs4hI6lDwXEmqW83zli0HB8rz5oVOcBC+EGRkwHe/G9rW7twJO3YcvB7v\nn1adOiGIbtas8Da+BZeOHSu+icHixaFN8IYNoTnOeedV7PWqit27QyC7Z08IavfsOXi9ItL274ez\nzoJTT62aQ+wtXw6/+U2oHW/QIDQjuemm8OWvNBQ8i4ikjuKe2eowmEATJxbe5nnixOSVKV47d8KC\nBQeC5HnzYOXKA/uPPRb69oUTT4SsrDDqQcOGRefnHoKwvIC6YGC9Ywds3Vr4cGubNoU2xnlDr+3Z\nc3DetWqFn9HHjq2YGspXXoFLLgkd9/7973Cv6SJvQhE54HvfC1+gbr01BNH33gtXX1364FlERKoH\nBc8JlNcpMJVG23jhBRg/PtS05jUtad06BMkjR4bXnj3DcGelYXYgEGvZsuzlcw+1obHjGP/tb6FN\n6v/+L0ydCr17lz3/gv78Z/j5z6FbtzBCRevWictbUlvnzqHt+5dfhnbZIiKSnhQ8J1h2dtUOlvNs\n2ADXXx9+iu7SJdTi5tUqH3lkskt3gFmova9fPzQRgVADPnRo6FD2P/8Tfka/445wTFnt3Rva2/7p\nT2FYtKeeKr5mXdKXAmcRkfSm4DkNPfcc/PSnoXnEb34TmkCkwigRsc46K4wF/KtfhVEaXnwxDDE2\nYEDp89q+PQTjs2aFAPruu8OwcyIiIiIF1Uh2AaTyfPUVXHwxXHhhaI4wfz7cfnvqBc55GjeGv/4V\nXn89bA8cGNqibtsWfx6ffRZqsmfPDnnde68CZxERESmaguc04A7PPBPabL74YmiH/e67oV1vdTBw\nICxaFGqNH3oo3OesWSWf95//QK9eYYSUV14JzUBEREREiqPguZr78stQ0zx0aJj9bsGCMGpA7drJ\nLlli1a8fao3ffjvUSP/gB3D55bBxY+HHP/ss9O8fznvnHTjttMotr4iIiKQmBc/VlHvo9JaRAS+/\nDL//fQgsO3dOdskqVu/e4QvC2LGhM2RGRgiU87jDXXfBRRfBCSeEGviMjOSVV0RERFKLgudq6PPP\nw6Qe2dlhjNr33w8d62qlSffQOnXC6Bs5OaFt90UXwQUXhPbNP/pRqHkfNiy0lS7vlMsiIiKSXuIK\nns1ssJktM7OVZja6kP1tzexfZrbIzN4ws9Yx+64wsxXRckVMek8zWxzl+YBZVZxbLLW4h6mEMzLg\nn/+Ee+4J0y136pTskiVH9+7w3nuhpvnll8OshI8+CuPGhUkvquq04CIiIlJ1lVgXaWY1gcnAaUAu\nMM/MZrr70pjD7gEed/fHzGwQcBdwmZkdDowDsgAH5kfnbgYeBH4MvAfMAgYDryTu1lLD9u2hpjhv\n2bgxjPZQu3ZYatU6+LWotL17w2QnL78cRo+YOjXUOqe7vNkIhwwJTTnOPz/UOouIiIiURTw/5PcC\nVrr7KgAzmw6cC8QGzxnAjdH6HOCFaP0M4FV33xSd+yow2MzeABq7+7tR+uPAeVST4Nk9zIYXGxSv\nW3fwdl7azp2Ju269ejBpElx7rYZbK6hjR/h//y/ZpRAREZFUF0/w3ApYE7OdCxScEPkD4HzgfmAI\n0MjMmhdxbqtoyS0kPSXt2xeGSnvjjbDMnRuC54IaNoSjjgpLZmYYEeKoo8LMeXnpzZuHabL37Am1\nybGvRa3nvfbqBW3bVvbdi4iIiKSPRHUhuwn4s5mNAOYCa4F9icjYzEYBowDatGmTiCzLrbhguUOH\nMDRcRsaBgDhvadQomaUWERERkfKKJ3heCxwds906Ssvn7usINc+YWUPgAnffYmZrgQEFzn0jOr91\ngfSD8ozJewowBSArK8vjKG/C7d9/aLC8eXPY16FDGM1hwIAwbnCrlK0/FxEREZGSxBM8zwM6mFl7\nQoA7FLg09gAzawFscvf9wC3A1GjXbOBOM2sWbZ8O3OLum8xsm5n1IXQYvBz4U7nvJoG2bAkjMxQM\nlo87Lgx7lhcst25dTCYiIiIiUq2UGDy7+14zu5YQCNcEprr7EjObAOS4+0xC7fJdZuaEZhs/i87d\nZGZ3EAJwgAl5nQeBnwKPAvUIHQWrTGdB91Cb/NprCpZFRERE5IC42jy7+yzCcHKxabfHrD8LPFvw\nvGjfVA7URMem5wBdSlPYyvKTn4TAGUJHvAEDwoQjIiIiIpLeNMNgAX/+Mzz00IHtTz+FUaPCpBoi\nIiIikt4UPMdwD9NYF7RrF4wZU/nlEREREZGqRcFzjGefhd27C9/32WeVWxYRERERqXoUPEc2bgwz\n8x12WOH7q8gQ0yIiIiKSRAqeIzfcAJs2wfjxUL/+wfvq14eJE5NSLBERERGpQhQ8A7NmwRNPwC23\nhGXKlDDNtVl4nTJFo22IiIiISOKm505Z27bB1VeH6bTzOgVmZytYFhEREZFDpX3wfMstkJsLb78N\ndeokuzQiIiIiUpWldbONuXPhL3+BX/wC+vRJdmlERCqWmU01s6/M7MMi9puZPWBmK81skZllxuy7\nwsxWRMsVlVdqEZGqJW2D59274aqroH17uOOOZJdGRKRSPAoMLmb/mUCHaBkFPAhgZocD44DeQC9g\nnJk1q9CSiohUUWkbPI8fDytWhNkEGzRIdmlERCqeu88FNhVzyLnA4x68CzQ1s6OAM4BX3X2Tu28G\nXqX4IFxEpNpKy+A5JwfuuSfUPJ9ySrJLIyJSZbQC1sRs50ZpRaWLiKSdtAue9+yBK6+EI4+EP/wh\n2aUREalezGyUmeWYWc769euTXRwRkYRLu+D597+HRYvgwQehadNkl0ZEpEpZCxwds906Sisq/RDu\nPsXds9w9q2XLlhVWUBGRZEmr4Hnp0tA58JJL4Jxzkl0aEZEqZyZweTTqRh9gq7t/DswGTjezZlFH\nwdOjNBGRtJM24zzv2xeaazRqBA88kOzSiIhUPjN7GhgAtDCzXMIIGrUB3P2vwCzgLGAlsAsYGe3b\nZGZ3APOirCa4e3EdD0VEqq20CZ7//Gd491148kk44ohkl0ZEpPK5+7AS9jvwsyL2TQWmVkS5RERS\nSVo02/jkE7j1VjjrLLj00mSXRkRERERSVbUPnt1h1CioWRP++lcwS3aJRERERCRVVftmG488Aq+9\nFkbXOProko8XERERESlKta55XrcObrwRTj451D6LiIiIiJRHtQ6e69eHYcPg4YehRrW+UxERERGp\nDNW62UbTpqG5hoiIiIhIIqg+VkREREQkTgqeRURERETipOBZRERERCROCp5FREREROKk4FlERERE\nJE4KnkVERERE4qTgWUREREQkTnEFz2Y22MyWmdlKMxtdyP42ZjbHzN43s0VmdlaUnm1mC2OW/WbW\nI9r3RpRn3r4jEntrIiIiIiKJVeIkKWZWE5gMnAbkAvPMbKa7L405bCwww90fNLMMYBbQzt2nAdOi\nfLoCL7j7wpjzst09J0H3IiIiIiJSoeKpee4FrHT3Ve7+LTAdOLfAMQ40jtabAOsKyWdYdK6IiIiI\nSEqKJ3huBayJ2c6N0mKNB4abWS6h1vm6QvK5BHi6QNojUZON28zM4iuyiIiIiEhyJKrD4DDgUXdv\nDZwFPGFm+XmbWW9gl7t/GHNOtrt3BU6KlssKy9jMRplZjpnlrF+/PkHFFREREREpvXiC57XA0THb\nraO0WFcCMwDc/R2gLtAiZv9QCtQ6u/va6HU78BShecgh3H2Ku2e5e1bLli3jKK6IiIiISMWIJ3ie\nB3Qws/ZmdhghEJ5Z4JjPgFMAzKwTIXheH23XAC4mpr2zmdUysxbRem3gh8CHiIiIiIhUYSWOtuHu\ne83sWmA2UBOY6u5LzGwCkOPuM4FfAg+Z2Q2EzoMj3N2jLE4G1rj7qphs6wCzo8C5JvAa8FDC7kpE\nREREpAKUGDwDuPssQkfA2LTbY9aXAn2LOPcNoE+BtJ1Az1KWVUREREQkqTTDoIiIiIhInBQ8i4iI\niIjEScGziIiIiEicFDyLiIiIiMRJwbOIiIiISJwUPIuIiIiIxEnBs4iIiIhInBQ8i4iIiIjEScGz\niIiIiEicFDyLiIiIiMRJwbOIiIiISJwUPIuIiIiIxEnBs4iIiIhInBQ8i4iIiIjEScGziIiIiEic\nFDyLiKQJMxtsZsvMbKWZjS5k/31mtjBalpvZlph9+2L2zazckouIVB21kl0AERGpeGZWE5gMnAbk\nAvPMbKa7L807xt1viDn+OuCEmCx2u3uPyiqviEhVpZpnEZH00AtY6e6r3P1bYDpwbjHHDwOerpSS\niYikEAXPIiLpoRWwJmY7N0o7hJm1BdoDr8ck1zWzHDN718zOK+oiZjYqOi5n/fr1iSi3iEiVouBZ\nREQKGgo86+77YtLaunsWcCkwycyOLexEd5/i7lnuntWyZcvKKKuISKVS8Cwikh7WAkfHbLeO0goz\nlAJNNtx9bfS6CniDg9tDi4ikDQXPIiLpYR7Qwczam9lhhAD5kFEzzOx4oBnwTkxaMzOrE623APoC\nSwueKyKSDjTahohIGnD3vWZ2LTAbqAlMdfclZjYByHH3vEB6KDDd3T3m9E7A38xsP6HS5Xexo3SI\niKQTBc8iImnC3WcBswqk3V5ge3wh570NdK3QwomIpAg12xARERERiZOCZxERERGROCl4FhERERGJ\nk4JnEREREZE4KXgWEREREYmTgmcRERERkTjFFTyb2WAzW2ZmK81sdCH725jZHDN738wWmdlZUXo7\nM9ttZguj5a8x5/Q0s8VRng+YmSXutkREREREEq/E4NnMagKTgTOBDGCYmWUUOGwsMMPdTyAMsP+X\nmH0fu3uPaLk6Jv1B4MdAh2gZXPbbEBERERGpePHUPPcCVrr7Knf/FpgOnFvgGAcaR+tNgHXFZWhm\nRwGN3f3daBarx4HzSlVyEREREZFKFk/w3ApYE7OdG6XFGg8MN7NcwuxV18Xsax8153jTzE6KyTO3\nhDxFRERERKqURHUYHAY86u6tgbOAJ8ysBvA50CZqznEj8JSZNS4mn0OY2SgzyzGznPXr1yeouCIi\nIiIipRdP8LwWODpmu3WUFutKYAaAu78D1AVauPs37r4xSp8PfAx8Lzq/dQl5Ep03xd2z3D2rZcuW\ncRRXRERERKRixBM8zwM6mFl7MzuM0CFwZoFjPgNOATCzToTgeb2ZtYw6HGJmxxA6Bq5y98+BbWbW\nJxpl43LgxYTckYiIiIhIBalV0gHuvtfMrgVmAzWBqe6+xMwmADnuPhP4JfCQmd1A6Dw4wt3dzE4G\nJpjZHmA/cLW7b4qy/inwKFAPeCVaRERERESqrBKDZwB3n0XoCBibdnvM+lKgbyHnPQc8V0SeOUCX\n0hRWRERERCSZNMOgiIiIiEicFDyLiIiIiMRJwbOIiIiISJwUPIuIiIiIxEnBs4iIiIhInBQ8i4iI\niIjEScGziIiIiEicFDyLiIiIiMRJwbOIiIiISJwUPIuIiIiIxEnBs4iIiIhInBQ8i4iIiIjEScGz\niIiIiEicFDyLiIiIiMRJwbOIiIiISJwUPIuIiIiIxEnBs4iIiIhInBQ8i4iIiIjEScGziIiIiEic\nFDyLiIiIiMRJwbOIiIiISJwUPIuIpBEzG2xmy8xspZmNLmT/CDNbb2YLo+WqmH1XmNmKaLmicksu\nIlI11Ep2AUREpHKYWU1gMnAakAvMM7OZ7r60wKHPuPu1Bc49HBgHZAEOzI/O3VwJRRcRqTJU8ywi\nkj56ASvdfZW7fwtMB86N89wzgFfdfVMUML8KDK6gcoqIVFkKnkVE0kcrYE3Mdm6UVtAFZrbIzJ41\ns6NLc66ZjTKzHDPLWb9+faLKLSJSZSh4FhGRWC8B7dy9G6F2+bHSnOzuU9w9y92zWrZsWSEFFBFJ\nJgXPIiLpYy1wdMx26ygtn7tvdPdvos2HgZ7xnisikg4UPIuIpI95QAcza29mhwFDgZmxB5jZUTGb\n5wAfReuzgdPNrJmZNQNOj9JERNKKRtsQEUkT7r7XzK4lBL01ganuvsTMJgA57j4TuN7MzgH2ApuA\nEdG5m8zsDkIADjDB3TdV+k2IiCSZgmcRkTTi7rOAWQXSbo9ZvwW4pYhzpwJTK7SAIiJVXFzNNuIY\nVL+Nmc0xs/ejHtpnRemnmdl8M1scvQ6KOeeNKM+8gfiPSNxtiYiIiEi6c098niUGzzGD6p8JZADD\nzCyjwGFjgRnufgKhDd1fovQNwNnu3hW4AniiwHnZ7t4jWr4qx32IiIiIiOTLyYE+fWDx4sTmG0/N\nczyD6jvQOFpvAqwDcPf33X1dlL4EqGdmdcpfbBERERGRQ23fDj//OfTuDWvWwFcJrp6NJ3iOZ2D8\n8cBwM8sltKW7rpB8LgAWxAyBBPBI1GTjNjOz+IstIiIiInKwF16ATp3gT3+Ca66Bjz6CU05J7DUS\nNVTdMOBRd28NnAU8YWb5eZtZZ+D3wE9izsmOmnOcFC2XFZaxZqsSERERkeKsWQPnnQdDhkDz5vDO\nO/DnP0OTJom/VjzBczwD418JzABw93eAukALADNrDTwPXO7uH+ed4O5ro9ftwFOE5iGH0GxVIiIi\nIlKYffvg/vshIwP++U+4++7Q1rl374q7ZjzBc4mD6gOfAacAmFknQvC83syaAi8Do939//IONrNa\nZpYXXNcGfgh8WN6bEREREZH0MH9+CJJ/8Qs46SRYuhRuvhlq167Y65YYPLv7XiBvUP2PCKNqLDGz\nCdFA+gC/BH5sZh8ATwMj3N2j844Dbi8wJF0dYLaZLQIWEmqyH0r0zYmIiIhI4rhXzPBvpbFjB9xw\nA/TqBWvXwowZ8PLL0K5d5Vw/rklS4hhUfynQt5Dzfgv8tohse8ZfTBERERFJpg8+gEsvDTW8NWpA\nrVphqVmz8PWC23XqwDHH/P/t3XuQVOWZx/Hvw02DNwZhBR0YMEIUynjJaDRmjSxy0UrU3VIKC2vN\nxgIxMZfNZrNapCyTkiSaSlK1VtZdzEVjiKLuspItFaJgUpWoYUiQCMpFBARREQiCyP3ZP97T6TM9\n3dOHvp7u+X2qTvXpc+nzzOmZl4f3vBcYPTosH/lIeD3xxOLXzliwAG69FTZvhpkz4dvfhgEDqvcz\n56MZBkVERESkIHe4/3740pdg4ED4xjfCtsOH4dCh7BJ/n2/f++/Diy/CvHmda69POSWbSMcT69NP\nh379wjGbN4frz58PZ58dPuPii+tzP5Q8i4iIiEheu3fDzTfDww/DhAnwi1/A35Q5J/S+fbB+Paxe\nDWvWhGX1anjiCYgPrNarF4wcCWecAb//fUjCv/td+OpXq9+uuTtKnkVERESkixUr4LrrYN06uOsu\nuP32kNCW69hjw+gYY3LnqwZ27swm1PHEevx4+P73Q210vSl5FhEREZG/cocf/zg0k2hpgcWL4VOf\nqs21W1rCCBrVHGqu09C3SQAAFIxJREFUXJWaJEVEREREGtzu3XDDDTBjRhj+bfny2iXOjULJs4iI\niEgDeu892L+/cp+3YgW0t8Mjj4RmGk8/XX775mak5FlERESkgRw8GIZoGzw4jH7x6U/DvffC2rWl\njcGcGU3j4x8PNc+LF8OsWZVp39yM1OZZREREpEEsWwY33RTGXL72WhgyBBYuDJOEQOhQN2kSTJ4M\n48bBCSd0/3m7d4fxkn/5y8qNptHslDyLiIiIpNzevXDnnWHEiVNOCeMdX3NNdv9rr4UkeuFC+PnP\n4b77wnBul1wSEunJk+GjHwWz7DnVGk2j2Sl5FhEREUmx556D6dNDkjt9OtxzT9dZ9T78Yfj858Ny\n4AD87nchkX76abjttrAMGRJqpSdNgr/8JYyXPGAAPPssXHZZPX6yxqTkWURERCSFdu2Cr38d5swJ\nyfHixaEpRjH9+oXjxo0Lk4ps3QqLFoVE+le/ggcfDMdNmAAPPRRqsiU5Jc8iIiIiKbNgAdxyC7z1\nFnzta/DNb0L//qV91tChcOONYTl8OLSb3ro1dDTs3buycfcESp5FREREUuKdd8LkJPPmhTbKTzwR\nho+rlN694cILK/d5PZGahYuIiIjUmXtoQnHWWaEz4F13QUdHZRNnqQzVPIuIiEhD2rsX3nwzu2zZ\nEl537IAzzwyJZ3s7nHRSvSPt3saNcPPNoYPfJz4RpsY+66x6RyWFKHkWERGR1Nm+Hdas6Zwc5ybJ\nu3Z1Pe9DHwojSDzwQHbb6NEhib7ggvB63nlw3HE1+1E6OXIEXn8dVq2ClSvDMn9+2HfvvWG0DA0X\nl25KnkVERKTuDhyA558Po0IsWhQ6tcVny+vbF049NSxjxsDll2ffZ5bTToMTTwxjGe/YEZo9LF0a\nXn/zmzARCITkdOzYbEJ9wQVw9tlwzDGV+3kOH4YNG0JyHE+UX30VPvgge1xra+i4d/fd0NZWuetL\n9Sh5FhGR1LjlFmhpCRM3nHtu5wkdpLm4w+rV2WT5uefg/fdDh7aLLw6jS3zsYyEhPvVUOPnko6uR\nHTgQJk4MS8bWrdmEeunSMKLFz34W9vXrFzronXFGSKL79Su89O3bdVuvXrB+fTZZfuUV2Lcve+3W\n1pCwX3ZZeB07NjTNSHuTEulKybOIiKTCkSPwxhtw//3wne+EJOa665RIN5Pt28OEHJmE+Y03wvZR\no8IwahMnhrGJTzyxOtcfOhQ+85mwQEjgN27M1k5nkuqDB0NNeO6SxLBhoWZ83LiQII8ZE5Zq/UxS\ne+bxZyIp197e7h0dHfUOQ0TkqJnZMnfvUf3mSy2z3303tAF99FFYsiQ8/s4k0lOmwDnnKJFuBEeO\nhGHXXn0VnnkmJMsdHSFhHTAAxo8PyfKECTByZL2jLc49/C7mS6oPHIBDh2D4cCXJzaK7MlvJs4hI\nDSh5Ls22bSGRfuyxzon0lCkhmT7nnNCOddYs2LQpJC+zZ8O0aRX6ISSvI0fg7bdh8+ZQexx/zay/\n+WaowYXQFOOii7LNKNrboY+efUuKKXkWEakzJc/ly5dIDxkSaqoPHcoe179/mM5YCXSoLd26Fdau\nzY5ccfhw2O4ekuDc9ULb3n03mxxv2dL5nkNoJ9zaGpZhw7KvI0bAJZeoba80lu7KbP2/T0REGsLg\nwTBjRlgyifSXv9w1idu7F6ZPD80Ejj8+LCeckP81s96nT6glPXgwfF5mvdj7Q4eyI0LE66KSrPfr\nFzq1DRwYOsNl1ksZ8WH79myCnHnNrL//ftfjzUIHN7PC6/FtZiHG1la49NKuSXJrKwwapOY00jMo\neRYRkYaTSaRnzsy//4MP4Le/hd27Yc8e2L+/tvGV47jjuibUmfWTTw41uG+91TlB3rEje37v3qG2\nd/TokOiOHh2WUaNCstu7d91+NJGmoORZREQa1vDhYbSEXG1tYSKKjIMHQxK9Z082oc687tkT9vft\nm1369Cn8Pnc9PnxavOa12Pq+fbBzZ0h8t28Pr/H1zOvKldn1eC17a2tIiqdMCYlxJkEeOTLUaotI\ndSh5FhGRhjV7dqiB3rs3u61//7A9rm/fMH50S0tt4ytmxIjkx7qHRH/nztBEon//qoUlIt3QBJAi\nItKwpk0LnQPb2kKNbltb83YWNAvts4cPV+IsUk9KnkVEeggzm2xmq81snZndlmf/V81slZmtMLNn\nzawttu+wmS2PlgW1jbx706aFaZCPHAmvzZg4i0h6KHkWEekBzKw38CPgCmAMcL2Zjck57E9Au7t/\nFHgcuCe27wN3PzdarqpJ0DUwd25oOtGrV3idO7feEYlI2il5FhHpGS4E1rn7enc/ADwCXB0/wN2X\nuHum9fALQGuNY6ypuXNDe+mNG7PTNM+YoQRaRLqXKHlO8KhvuJktMbM/RY/7roztuz06b7WZTUr6\nmSIiUlGnAW/E3m+OthVyE/BU7P2xZtZhZi+Y2TWFTjKzGdFxHdu2bSsv4iqbNatzR0MI72fNqk88\nItIYio62EXvUN4FQ2C41swXuvip22DeAR939vugx4JPAiGh9KjAWOBV4xsxGR+cU+0wREakDM7sB\naAc+Fdvc5u5bzOx0YLGZ/dndX8s9193nAHMgzDBYk4BLtGnT0W0XEYFkNc9FH/UBDpwYrZ8EvBmt\nXw084u773f11YF30eUk+U0REKmcLMCz2vjXa1omZXQ7MAq5y979OLeLuW6LX9cBzwHnVDLYWhg8/\nuu0iIpAseU7yqO9O4AYz20yodf5ikXOP9vGhiIiUZykwysxGmlk/wlPBTqNmmNl5wH8REud3Yttb\nzOyYaH0QcAnQ8E8KZ8/uOuRbvjGiC1FnQ5GeqVIdBq8HHnD3VuBK4CEzq8hnN1L7ORGRtHL3Q8Ct\nwELgFUJTu5Vm9i0zy4ye8T3geOCxnCHpzgI6zOwlYAnw3WZoZlfOGNHqbCjScyWZYTDJo76bgMkA\n7v68mR0LDCpybtHHh9HnNUz7ORGRNHP3JwlPB+Pb7oitX17gvN8DZ1c3uvqYNq20caG762yocaZF\nmluS2uGij/qATcB4ADM7CzgW2BYdN9XMjjGzkcAo4A8JP1NERCSV1NlQpOcqmjwnfNT3L8D06JHe\nw8BnPVgJPEpoG/c08AV3P1zoMyv9w4mIiFRDOZ0N1VZapLElabaR5FHfKkIHknznzga6dL/I95ki\nIiKNYPbs0MY53nQjSWfDTFvpzHmZttKg5h4ijUIzDIqIiBylUjsbljsxi2qtReovUc2ziIiIdFZK\nZ8Ny2kqr1lokHVTzLCIiUiPltJXWdOIi6aDkWUREpEbKmZil3FprNfcQqQwlzyIiIjVSzsQspdZa\na0IXkcpS8iwiIlJD06bBhg1w5Eh4TdpeudRaa3VSFKksJc8iIiINoNRa60p0UlSttUiWkmcREZEG\nUUqtdb06KarGWpqVkmcREZEmVo9OiuXWWCvxljRT8iwiItLE6tFJsdwaazUVkTRT8iwiItLkat1J\nsZx21hrPWtJOybOIiIjkVWqtdTntrMtJvMuhpiKSlJJnERERKaiUWuty2lmXk3hDaUmwmorI0VDy\nLCIiIhVVTjvrchLvUpNgjYUtR0PJs4iIiFRcqe2sy0m8S02C6zUWtpLuxqTkWURERFKl1MS71CS4\nHmNhq6lI41LyLCIiIk2h1CS4HmNhq6lI41LyLCIiIk2h1CS4HmNhN2JTESXsgZJnERERaQrlJMG1\nHgu70ZqKNGLb7mpdt6mTZ/0PSUREpGcpNQku53qlJOyN1lSkXm27S83lqtmm3Ny9/E+pkfb2du/o\n6Eh0bOamxb/o/v2T/w9URKSSzGyZu7fXO45aOpoyW6Qnmjs3JJ+bNoUa59mzk+UoI0aEZDBXW1v4\nD0MhvXqFRDKXWfjPRndKPbfUWKG8XK6c60L3ZXbT1jxrek8RERFJs0ZqKlKPtt3l5HLVnKmyaZPn\nek3vKSIiIlJN9WgqUo+EvZxcrtyZKrvTtMlzNW+aiIiISD2VUmtdbofKWifs5eRy5Vy3mKZNnqt5\n00REREQaUTkdKmudsJeTy5Vz3WL6lP8R6ZS5OaU0xBcRERGRypg2rbT8q9xcrtTrFtO0yTNU76aJ\niIiISPWlMZdr2mYbIiIiIiKVpuRZRERERCQhJc8iIiIiIgklSp7NbLKZrTazdWZ2W579PzSz5dGy\nxsz+Em0fF9u+3Mz2mdk10b4HzOz12L5zK/ujiYiIiIhUVtEOg2bWG/gRMAHYDCw1swXuvipzjLv/\nc+z4LwLnRduXAOdG2wcC64BFsY//V3d/vAI/h4iIiIhI1SWpeb4QWOfu6939APAIcHU3x18PPJxn\n+7XAU+6+N88+EREREZHUS5I8nwa8EXu/OdrWhZm1ASOBxXl2T6VrUj3bzFZEzT6OSRCLiIiUIUEz\nvGPMbF60/0UzGxHbd3u0fbWZTapl3CIiaVHpDoNTgcfd/XB8o5kNBc4GFsY23w6cCVwADAT+Ld8H\nmtkMM+sws45t27ZVOFwRkZ4j1gzvCmAMcL2Zjck57CZgp7ufAfwQuDs6dwyhjB8LTAb+I/o8EZEe\nJUnyvAUYFnvfGm3LJ1/tMsAUYL67H8xscPetHuwHfkZoHtKFu89x93Z3bx88eHCCcEVEpIAkzfCu\nBh6M1h8HxpuZRdsfcff97v46oQ9L3nJbRKSZJUmelwKjzGykmfUjJMgLcg8yszOBFuD5PJ/RpR10\nVBtNVChfA7x8dKGLiMhRStIM76/HuPshYBdwcsJz9bRQRJpe0dE23P2Qmd1KaHLRG/ipu680s28B\nHe6eSaSnEmolPH5+1F5uGPCbnI+ea2aDAQOWAzOLxbJs2bJ3zWxjsePyGAS8W8J51aJ4iktbTGmL\nB9IXU9rigXTF1FbvAGrB3ecAcwDMbJvK7KpJW0xpiwfSF5PiKS5NMRUss4smzwDu/iTwZM62O3Le\n31ng3A3kqZ1w979Lcu2cc0pqt2FmHe7eXsq51aB4iktbTGmLB9IXU9rigXTGVGdJmuFljtlsZn2A\nk4DtCc/tRGV29aQtprTFA+mLSfEUl8aY8tEMgyIiPUeSZngLgBuj9WuBxdETxQXA1Gg0jpHAKOAP\nNYpbRCQ1EtU8i4hI40vYDO8nwENmtg7YQUiwiY57FFgFHAK+kDuykohIT9BTkuc59Q4gh+IpLm0x\npS0eSF9MaYsH0hlTXRVrhufu+4DrCpw7G5hd1QCDtH1vaYsH0hdT2uKB9MWkeIpLY0xdWE7/PhER\nERERKUBtnkVEREREEmqa5LmcKWerFM8wM1tiZqvMbKWZfTnPMZeZ2S4zWx4td+T7rArGtMHM/hxd\nqyPPfjOzf4/u0QozO7/K8Xwk9rMvN7P3zOwrOcdU9R6Z2U/N7B0zezm2baCZ/drM1kavLQXOvTE6\nZq2Z3ZjvmArG9D0zezX6Xuab2YAC53b7HVcwnjvNbEvse7mywLnd/l1WMJ55sVg2mNnyAudW/P5I\n6dJUbqexzI6umZpyOw1ldnSNVJXbKrNLjqlxy213b/iF0PHlNeB0oB/wEjAm55jPA/8ZrU8F5lU5\npqHA+dH6CcCaPDFdBvxfDe/TBmBQN/uvBJ4ijL19EfBijb/Dt4C2Wt4j4FLgfODl2LZ7gNui9duA\nu/OcNxBYH722ROstVYxpItAnWr87X0xJvuMKxnMn8LUE32m3f5eViidn//eBO2p1f7SU/D2mqtxO\nY5kdXTOV5Xa9yuzoGqkqt1VmlxZTzv6GKrebpea5nClnq8LD9ON/jNZ3A6+QZ7zrlLka+LkHLwAD\nLJoJsgbGA6+5eykTKpTM3X9LGFEgLv678iBhBsxck4Bfu/sOd98J/BqYXK2Y3H2Rh9neAF4gjLFb\nEwXuURJJ/i4rGk/0Nz2FnBlNJZVSVW43aJkN9Su361JmQ/rKbZXZ5cXUiOV2syTP5Uw5W3XRo8bz\ngBfz7L7YzF4ys6fMbGyVQ3FgkZktM7MZefYnmn63SqZS+A+nlvcI4BR33xqtvwWckueYet6rzxFq\nmvIp9h1X0q3RI8mfFnhEWo979LfA2+6+tsD+Wt4f6V5qy+0UldmQ3nI7TWU2pLvcVpndvYYrt5sl\neU4tMzse+G/gK+7+Xs7uPxIeeZ0D3Av8b5XD+aS7nw9cAXzBzC6t8vUSsTBZw1XAY3l21/oedeLh\nmVFqhqQxs1mEMXbnFjikVt/xfcCHgXOBrYRHbmlwPd3XXqTyb0DSI2VlNqTwdzbNZTakq9xWmZ1I\nw5XbzZI8H82Us1jnKWerxsz6Egrhue7+P7n73f09d98TrT8J9DWzQdWKx923RK/vAPMJj2jijnr6\n3Qq5Aviju7+du6PW9yjyduaxZ/T6Tp5jan6vzOyzwKeBadE/Dl0k+I4rwt3fdvfD7n4EuL/AdWp6\nj6K/638A5hU6plb3RxJJXbmdtjI7uk4ay+20ldmQwnJbZXZxjVpuN0vyXM6Us1URteH5CfCKu/+g\nwDFDMu33zOxCwvdRlX8YzOw4Mzshs07ozPByzmELgH+04CJgV+wxWDUV/F9nLe9RTPx35UbgiTzH\nLAQmmllL9PhrYrStKsxsMvB14Cp331vgmCTfcaXiibep/PsC10nyd1lJlwOvuvvmfDtreX8kkVSV\n22krs6NrpLXcTluZDSkrt1VmJ9aY5XbSnoVpXwg9jtcQeorOirZ9i/CLC3As4RHTOuAPwOlVjueT\nhMdGK4Dl0XIlMBOYGR1zK7CS0KP1BeATVYzn9Og6L0XXzNyjeDwG/Ci6h38G2mvwvR1HKFhPim2r\n2T0i/AOwFThIaN91E6FN5bPAWuAZYGB0bDvw49i5n4t+n9YB/1TlmNYR2qJlfpcyIxCcCjzZ3Xdc\npXgein5HVhAK16G58UTvu/xdViOeaPsDmd+b2LFVvz9ayvouU1Nuk7IyO7pe6spt6lxmR9dIVbld\nIB6V2UViirY/QAOW25phUEREREQkoWZptiEiIiIiUnVKnkVEREREElLyLCIiIiKSkJJnEREREZGE\nlDyLiIiIiCSk5FlEREREJCElzyIiIiIiCSl5FhERERFJ6P8BSTvRP8xFhNQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMoqCQ3qdCCz",
        "colab_type": "text"
      },
      "source": [
        "#### A few techniques that can reduce overfitting:\n",
        "    * Regularisation of data (L1 or L2).\n",
        "    * Dropouts â€” Randomly dropping connections between neurons, forcing the network to find new paths and generalise.\n",
        "    * Early Stopping â€” Precipitates the training of the neural network, leading to reduction in error in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-eYcIfn9Ped",
        "colab_type": "text"
      },
      "source": [
        "**You can add a dropout layer to overcome the problem of overfitting to some extent. Dropout randomly turns off a fraction of neurons during the training process, reducing the dependency on the training set by some amount.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpfxmw6QICoM",
        "colab_type": "text"
      },
      "source": [
        "In a CNN, each neuron produces one feature map. Since dropout spatial dropout works per-neuron, dropping a neuron means that the corresponding feature map is dropped - e.g. each position has the same value (usually 0). So each feature map is either fully dropped or not dropped at all.\n",
        "\n",
        "Pooling usually operates separately on each feature map, so it should not make any difference if you apply dropout before or after pooling. At least this is the case for pooling operations like maxpooling or averaging.\n",
        "\n",
        "However, if you actually use element-wise dropout (which seems to be set as default for tensorflow), it actually makes a difference if you apply dropout before or after pooling. However, there is not necessarily a wrong way of doing it. Consider the average pooling operation: if you apply dropout before pooling, you effectively scale the resulting neuron activations by 1.0 - dropout_probability, but most neurons will be non-zero (in general). If you apply dropout after average pooling, you generally end up with a fraction of (1.0 - dropout_probability) non-zero \"unscaled\" neuron activations and a fraction of dropout_probability zero neurons. Both seems viable to me, neither is outright wrong.\n",
        "\n",
        "[This tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/) uses pooling before dropout and gets good results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEvCZp27JF7v",
        "colab_type": "code",
        "outputId": "fffa668f-a7da-49fc-be4c-139eb2bfbe89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Example of VGG-like convnet from Keras (dropout used after pooling)\n",
        "'''\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate dummy data **\n",
        "x_train = np.random.random((100, 100, 100, 3))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "x_test = np.random.random((20, 100, 100, 3))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
        "\n",
        "model = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors. **\n",
        "# this applies 32 convolution filters of size 3x3 each. **\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport numpy as np\\nimport keras\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Flatten\\nfrom keras.layers import Conv2D, MaxPooling2D\\nfrom keras.optimizers import SGD\\n\\n# Generate dummy data **\\nx_train = np.random.random((100, 100, 100, 3))\\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\\nx_test = np.random.random((20, 100, 100, 3))\\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\\n\\nmodel = Sequential()\\n# input: 100x100 images with 3 channels -> (100, 100, 3) tensors. **\\n# this applies 32 convolution filters of size 3x3 each. **\\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.25))\\n\\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.25))\\n\\nmodel.add(Flatten())\\nmodel.add(Dense(256, activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(10, activation='softmax'))\\n\\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\\n\\nmodel.fit(x_train, y_train, batch_size=32, epochs=10)\\nscore = model.evaluate(x_test, y_test, batch_size=32)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhrkFY7Q9Fd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "### Adding dropout into the network\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 10\n",
        "#################################\n",
        "# The neural network architecture\n",
        "#################################\n",
        "\n",
        "fashion_model = Sequential()\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))#, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.25))  ####### after maxpooling\n",
        "\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.25))  ####### after maxpooling\n",
        "\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))             \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.5))  ####### after maxpooling\n",
        "\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(Dropout(0.4))  ####### after activation\n",
        "fashion_model.add(Dense(num_classes, activation='softmax')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to731RRfKQmC",
        "colab_type": "code",
        "outputId": "9be46efc-dc0c-4777-cf92-4ab7a2d29a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "### Model compiling\n",
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "fashion_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 356,234\n",
            "Trainable params: 356,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhGb6l8PKetG",
        "colab_type": "code",
        "outputId": "a600a7f2-f3de-4fbb-c609-3080f8e1cbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 7s 137us/step - loss: 0.6398 - acc: 0.7646 - val_loss: 0.3843 - val_acc: 0.8622\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.4019 - acc: 0.8524 - val_loss: 0.3274 - val_acc: 0.8787\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 5s 105us/step - loss: 0.3530 - acc: 0.8712 - val_loss: 0.2994 - val_acc: 0.8903\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 5s 108us/step - loss: 0.3215 - acc: 0.8821 - val_loss: 0.2703 - val_acc: 0.9015\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.3044 - acc: 0.8884 - val_loss: 0.2665 - val_acc: 0.9005\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2912 - acc: 0.8922 - val_loss: 0.2579 - val_acc: 0.9042\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2793 - acc: 0.8952 - val_loss: 0.2504 - val_acc: 0.9077\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2712 - acc: 0.8981 - val_loss: 0.2362 - val_acc: 0.9121\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2613 - acc: 0.9041 - val_loss: 0.2336 - val_acc: 0.9115\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2597 - acc: 0.9038 - val_loss: 0.2291 - val_acc: 0.9156\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 5s 108us/step - loss: 0.2490 - acc: 0.9076 - val_loss: 0.2256 - val_acc: 0.9170\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2453 - acc: 0.9081 - val_loss: 0.2368 - val_acc: 0.9136\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2421 - acc: 0.9102 - val_loss: 0.2167 - val_acc: 0.9189\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2380 - acc: 0.9127 - val_loss: 0.2256 - val_acc: 0.9176\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 5s 105us/step - loss: 0.2314 - acc: 0.9139 - val_loss: 0.2129 - val_acc: 0.9219\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2330 - acc: 0.9130 - val_loss: 0.2160 - val_acc: 0.9207\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 5s 104us/step - loss: 0.2292 - acc: 0.9145 - val_loss: 0.2167 - val_acc: 0.9227\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2279 - acc: 0.9142 - val_loss: 0.2115 - val_acc: 0.9221\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 5s 106us/step - loss: 0.2264 - acc: 0.9157 - val_loss: 0.2140 - val_acc: 0.9218\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 5s 107us/step - loss: 0.2229 - acc: 0.9160 - val_loss: 0.2088 - val_acc: 0.9243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ZvnY_WLb39",
        "colab_type": "code",
        "outputId": "90c5201d-47a9-43b9-aa3b-41bd2f0a1ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 71us/step\n",
            "Test loss: 0.22133314504027365\n",
            "Test accuracy: 0.9209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9O73DXxLp0G",
        "colab_type": "code",
        "outputId": "e24e6fda-1d34-43e3-fe7c-3228f36cc74d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "accuracy = fashion_train_dropout.history['acc']\n",
        "val_accuracy = fashion_train_dropout.history['val_acc']\n",
        "loss = fashion_train_dropout.history['loss']\n",
        "val_loss = fashion_train_dropout.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(12,6))\n",
        "\n",
        "ax1.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax1.title.set_text('Training and validation accuracy')\n",
        "ax1.legend()\n",
        "#plt.figure()\n",
        "ax2.plot(epochs, loss, 'bo', label='Training loss')\n",
        "ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "ax2.legend()\n",
        "ax2.title.set_text('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAF1CAYAAAAa1Xd+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyHuZPPlMf4b",
        "colab_type": "text"
      },
      "source": [
        "### Data dearth dealing\n",
        "There are many use cases where the amount of training data available is restricted. If you are not able to collect more data then you could resort to data augmentation techniques.\n",
        "https://towardsdatascience.com/how-to-increase-the-accuracy-of-a-neural-network-9f5d1c6f407d\n",
        "https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6nSuqvve0c2",
        "colab_type": "text"
      },
      "source": [
        "#### <b>Question:</b>\n",
        "Which of the followings does data augmentation do?\n",
        "\n",
        "   A.  Adds more training data<br>\n",
        "   B.  Replaces training data<br>\n",
        "   C.  Does both<br>\n",
        "   D.  I donâ€™t know<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSFpJNjngJUP",
        "colab_type": "text"
      },
      "source": [
        "Technically, all the answers are correct â€” but the only way you know if a given definition of data augmentation is correct is via the context of its application.\n",
        "\n",
        "#### **What is data augmentation?**\n",
        "\n",
        "Data augmentation encompasses a wide range of techniques used to generate â€œnewâ€ training samples from the original ones by applying random jitters and perturbations (but at the same time ensuring that the class labels of the data are not changed).\n",
        "\n",
        "Our goal when applying data augmentation is to increase the generalizability of the model.\n",
        "\n",
        "Given that our network is constantly seeing new, slightly modified versions of the input data, the network is able to learn more robust features.\n",
        "\n",
        "At testing time we do not apply data augmentation and simply evaluate our trained network on the unmodified testing data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4wP-yndqMi6",
        "colab_type": "text"
      },
      "source": [
        "#### A simple data augmentation\n",
        "![alt text](https://drive.google.com/uc?id=1Ne089ybJL1Bv7VmAJwYJjDwkYcx7uHEF)\n",
        "\n",
        "**Left:** A sample of 250 data points that follow a normal distribution exactly.<br> **Right:** Adding a small amount of random â€œjitterâ€ to the distribution. This type of data augmentation increases the generalizability of our networks.<br>\n",
        "\n",
        "In the context of computer vision, we can obtain augmented data by applying simple geometric transforms, for example:<br>\n",
        "*random* <br>\n",
        "> translations<br>\n",
        "> rotation<br>\n",
        "> scaling<br>\n",
        "> shearing<br>\n",
        "> horizontal/ vertical flips\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUPeBi07Mj9x",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter tuning\n",
        "Instead of trying different values by hand, we will use ***GridSearchCV*** from ***Scikit-Learn*** to try out several values for our hyperparameters and compare the results. <br>\n",
        "To do cross-validation with **keras**, we will use the wrappers for the Scikit-learn API.<br>\n",
        "There are two warppers available:\n",
        "<font color='red'>keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_parms)</font>, which implements the Scikit-learn classifier interface,<br>\n",
        "<font color='red'>keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)</font>, which implemens the Scikit-learn regressor interface.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrzQC0UhMnQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPOZ3UQVpv6j",
        "colab_type": "text"
      },
      "source": [
        "#### Trying different weight initializations\n",
        "The first parameter we will try to optimized via cross-validation is different weight initializations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh1VLxS1pfX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Let's create a function that crteates the model while accepting the hyperparameters we want to tune\n",
        "\n",
        "num_classes = 10\n",
        "#################################\n",
        "# The neural network architecture\n",
        "#################################\n",
        "def create_model(init_mode = 'uniform'):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same', kernel_initializer=init_mode))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='linear',padding='same', kernel_initializer=init_mode))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='linear',padding='same', kernel_initializer=init_mode))\n",
        "  model.add(LeakyReLU(alpha=0.1))                  \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='linear', kernel_initializer=init_mode))\n",
        "  model.add(LeakyReLU(alpha=0.1))   \n",
        "  model.add(Dense(num_classes, activation='softmax', kernel_initializer=init_mode))    \n",
        "  ## compile model\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "  \n",
        "  return model         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NicYehuR3WRY",
        "colab_type": "code",
        "outputId": "f3ba1722-bac0-4230-c78a-a1b49a053c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "import tqdm\n",
        "import threading\n",
        "\n",
        "def provide_progress_bar(function, estimated_time, tstep=0.2, tqdm_kwargs={}, args = [], kwargs={}):\n",
        "  ##\n",
        "  ret = [None]  # Mutable var so the function can store its return value\n",
        "  def myrunner(function, ret, *args, **kwargs):\n",
        "    ret[0] = function(*args, **kwargs)\n",
        "\n",
        "  thread = threading.Thread(target=myrunner, args=(function, ret) + tuple(args), kwargs=kwargs)\n",
        "  pbar = tqdm.tqdm(total=estimated_time **tqdm_kwargs)\n",
        "\n",
        "  thread.start()\n",
        "  while thread.is_alive():\n",
        "    thread.join(timeout=tstep)\n",
        "    pbar.update(tstep)\n",
        "  pbar.close()\n",
        "  return ret[0]\n",
        "\n",
        "def progress_wrapped(estimated_time, tstep=0.2, tqdm_kwargs={}):\n",
        "  ### decorate a function to add a progres bar ###\n",
        "  def real_decorator(function):\n",
        "    @functools.wraps(function)\n",
        "    def wrapper(*args, **kwargs):\n",
        "      return provide_progress_bar(function, estimated_time=estimated_time, tstep=tstep, tqdm_kwargs=tqdm_kwargs, args=args, kwargs=kwargs)\n",
        "    return wrapper\n",
        "  return real_decorator\n",
        "\n",
        "@progress_wrapped(estimated_time = 5)\n",
        "'''\n",
        "# Basic example\n",
        "retval = provide_progress_bar(long_running_function, estimated_time=5)\n",
        "print(retval)\n",
        "\n",
        "# Full example\n",
        "retval = provide_progress_bar(long_running_function,\n",
        "        estimated_time=5, tstep=1/5.0,\n",
        "        tqdm_kwargs={\"bar_format\":'{desc}: {percentage:3.0f}%|{bar}| {n:.1f}/{total:.1f} [{elapsed}<{remaining}]'},\n",
        "        args=(1, \"foo\"), kwargs={\"spam\":\"eggs\"}\n",
        "    )\n",
        "print(retval)\n",
        "\n",
        "# Example of using the decorator\n",
        "retval = another_long_running_function()\n",
        "print(retval)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-fde617fc70f8>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8JozjR5nw4g",
        "colab_type": "code",
        "outputId": "abf60934-e2ff-465a-8736-5a5738a3f970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "seed = 8\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "\n",
        "np.random.seed(seed)\n",
        "\n",
        "model_CV = KerasClassifier(build_fn=create_model, epochs = epochs, batch_size = batch_size, verbose = 1)\n",
        "## define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode = init_mode)\n",
        "grid = GridSearchCV(estimator = model_CV, param_grid = param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(train_X, train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "48000/48000 [==============================] - 6s 123us/step - loss: 0.4287 - acc: 0.8455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u-Z5CXuxfWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print results\n",
        "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm9isXoKyDgQ",
        "colab_type": "text"
      },
      "source": [
        "#### cross-validation with more than one hyperparameter\n",
        "We can do cross-validation with more than one parameters simultaneously, effectively trying out combinations of them.<br>\n",
        "**Note: Cross-validation in neural networks is computationally expensive.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEpufsx-ye4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Let's perform a GridSearch for batch size, number of epochs and initializer combined now.\n",
        "### First, create a function that creates the model (required for KerasClassifier) \n",
        "### while accepting the hyperparameters we want to tune \n",
        "### we also pass some default values such as optimizer='Adam'\n",
        "\n",
        "def create_model2(optimizer ='Adam', init = 'glorot_uniform'):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='linear',padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='linear',padding='same', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.1))                  \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='linear', kernel_initializer=init))\n",
        "  model.add(LeakyReLU(alpha=0.1))   \n",
        "  model.add(Dense(num_classes, activation='softmax', kernel_initializer=init))    \n",
        "  ## compile model\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer ,metrics=['accuracy'])\n",
        "  \n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqatLSsWMpEk",
        "colab_type": "text"
      },
      "source": [
        "### Algorithm ensemble\n",
        "If individual neural networks are not as accurate as you want, you can create an ensemble of neural networks and combine their predictive power. For example:\n",
        "* Choose different neural network architectures\n",
        "* Train them on different parts of the data\n",
        "* Ensemble them and use their collective predictive power to get high accuracy on test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnhbjkyTMsOc",
        "colab_type": "code",
        "outputId": "a952d3f0-2eea-4ea9-fbc0-2f390e228935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "### Supposedly you are building a cats vs dogs classifier, 0-cat and 1-dog. \n",
        "### When combining different cats vs dogs classifiers, \n",
        "### the accuracy of the ensemble algorithm increases based on the Pearson Correlation between the individual classifiers.\n",
        "\n",
        "### Let's look at the example below,\n",
        "'''\n",
        "Ground Truth: 1111111111\n",
        "Classifier 1: 1111111100 = 80% accuracy\n",
        "Classifier 2: 1111111100 = 80% accuracy\n",
        "Classifier 3: 1011111100 = 70% accuracy\n",
        "'''\n",
        "from scipy.stats import pearsonr as pr\n",
        "\n",
        "grnd_tru = [1,1,1,1,1,1,1,1,1,1]\n",
        "clfr1 = [1,1,1,1,1,1,1,1,0,0]\n",
        "clfr2 = [1,1,1,1,1,1,1,1,0,0]\n",
        "clfr3 = [1,0,1,1,1,1,1,1,0,0]\n",
        "\n",
        "r12, __ = pr(clfr1, clfr2)\n",
        "r13, __ = pr(clfr1, clfr3)\n",
        "r23, __ = pr(clfr2, clfr3)\n",
        "print('r12: %f, r13: %f, r23: %f' %(r12, r13, r23))\n",
        "\n",
        "### The Pearson Correlation of the three models is high. Therefore, ensembling them does not improve the accuracy. \n",
        "### If we ensemble the above three models using a majority vote, we get the following result.\n",
        "\n",
        "ensemble = [int((cl1+cl2+cl3)/3 > 0.5) for cl1, cl2, cl3 in zip(clfr1, clfr2, clfr3)]\n",
        "acc = [x == y for x, y in zip(grnd_tru, ensemble)]\n",
        "accuracy = sum(acc)/len(acc)\n",
        "print('accuracy =', accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r12: 1.000000, r13: 0.763763, r23: 0.763763\n",
            "accuracy = 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUtxjKhiqZN9",
        "colab_type": "code",
        "outputId": "2249ae0b-df56-4b6f-c995-2c95f43742e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "### Now let's look at three models having a very low Person Correlation between their outputs.\n",
        "'''\n",
        "Ground Truth: 1111111111\n",
        "Classifier 1: 1111111100 = 80% accuracy\n",
        "Classifier 2: 0111011101 = 70% accuracy\n",
        "Classifier 3: 1000101111 = 60% accuracy\n",
        "'''\n",
        "grnd_tru = [1,1,1,1,1,1,1,1,1,1]\n",
        "clfr1 = [1,1,1,1,1,1,1,1,0,0]\n",
        "clfr2 = [0,1,1,1,0,1,1,1,0,1]\n",
        "clfr3 = [1,0,0,0,1,0,1,1,1,1]\n",
        "\n",
        "r12, __ = pr(clfr1, clfr2)\n",
        "r13, __ = pr(clfr1, clfr3)\n",
        "r23, __ = pr(clfr2, clfr3)\n",
        "print('r12: %f, r13: %f, r23: %f' %(r12, r13, r23))\n",
        "\n",
        "###When we ensemble these three weak learners, we get the following result.\n",
        "ensemble = [int((cl1+cl2+cl3)/3 > 0.5) for cl1, cl2, cl3 in zip(clfr1, clfr2, clfr3)]\n",
        "acc = [x == y for x, y in zip(grnd_tru, ensemble)]\n",
        "accuracy = sum(acc)/len(acc)\n",
        "print('accuracy =', accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r12: 0.218218, r13: -0.408248, r23: -0.534522\n",
            "accuracy = 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IieSmT6h7C8J",
        "colab_type": "text"
      },
      "source": [
        "#### An ensemble of weak learners with low Pearson Correlation is able to outperform an ensemble with high Pearson Correlation between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qLvxk176-Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}